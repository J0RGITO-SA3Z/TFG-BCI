import os, sys, time, torch, numpy as np
import torch.nn as nn
from collections import deque
from sklearn.preprocessing import LabelEncoder

# === 1Ô∏è‚É£ Configuraci√≥n ===
MIREPNET_DIR = r"C:\Users\JORGE\OneDrive\Escritorio\Modelos BCI\Modelos\MIRepNet"
WEIGHT_PATH = os.path.join(MIREPNET_DIR, "weight", "MIRepNet.pth")
sys.path.append(MIREPNET_DIR)
from model.mlm import mlm_mask, PatchEmbedding

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üöÄ Usando dispositivo: {device}")

# === 2Ô∏è‚É£ Canales === Usando la primera configuraci√≥n valida para motor imagery
YOUR_HEADSET_CHANNELS_15 = ["F4","FCZ","FZ","FC3","F3","CZ","FC4",
                            "C4","CP4","P4","C3","CP3","PZ","CPZ","P3"]

TEMPLATE_45 = [
    'F7', 'F5', 'F3', 'F1', 'FZ', 'F2', 'F4', 'F6', 'F8',
    'FT7', 'FC5', 'FC3', 'FC1', 'FCZ', 'FC2', 'FC4', 'FC6', 'FT8',
    'T7', 'C5', 'C3', 'C1', 'CZ', 'C2', 'C4', 'C6', 'T8',
    'TP7', 'CP5', 'CP3', 'CP1', 'CPZ', 'CP2', 'CP4', 'CP6', 'TP8',
    'P7', 'P5', 'P3', 'P1', 'PZ', 'P2', 'P4', 'P6', 'P8'
]

# === 3Ô∏è‚É£ Proyector 14‚Üí45 ===
class ChannelProjector(nn.Module):
    def __init__(self, in_ch=15, out_ch=45):
        super().__init__()
        self.proj = nn.Conv1d(in_ch, out_ch, kernel_size=1, bias=False)
        self.reset_projection()

    def reset_projection(self):
        with torch.no_grad():
            self.proj.weight.zero_()
            for i, ch in enumerate(YOUR_HEADSET_CHANNELS_15):
                if ch.upper() in [c.upper() for c in TEMPLATE_45]:
                    j = [c.upper() for c in TEMPLATE_45].index(ch.upper())
                    self.proj.weight[j, i, 0] = 1.0

    def forward(self, x):
        return self.proj(x)  # [B,45,T]

# === 4Ô∏è‚É£ Modelo MIRepNet ===
model = mlm_mask(emb_size=256, depth=6, n_classes=3)
model.embedding = PatchEmbedding(embed_dim=256, num_channels=45)
model.to(device)

if os.path.isfile(WEIGHT_PATH):
    ckpt = torch.load(WEIGHT_PATH, map_location=device)
    model.load_state_dict(ckpt, strict=False)
    print("‚úÖ Pesos preentrenados cargados.")
else:
    print("‚ö†Ô∏è No se encontraron pesos.")

projector = ChannelProjector().to(device)
model.eval(); projector.eval()

# === 5Ô∏è‚É£ Configuraci√≥n de flujo ===
# Aqu√≠ deber√≠as importar tu SDK de BrainAccess:
# from brainaccess import EEGDevice
# deviceEEG = EEGDevice()
# deviceEEG.start_stream()

SAMPLE_RATE = 250        # Hz (ajusta a tu casco)
WINDOW_SEC = 4           # segundos por ventana (‚âà 480 muestras)
WINDOW_SIZE = SAMPLE_RATE * WINDOW_SEC
buffer = deque(maxlen=WINDOW_SIZE)

le = LabelEncoder().fit(["left_hand","right_hand","feet"])

# === 6Ô∏è‚É£ Bucle en tiempo real ===
print("üß† Esperando flujo EEG...")
while True:
    # Simulaci√≥n: datos aleatorios del casco (14 canales, N muestras nuevas)
    # En la pr√°ctica: data = deviceEEG.get_data(samples=N)
    new_data = np.random.randn(15, 10).astype(np.float32)  # 10 muestras nuevas

    # A√±adir al buffer
    for i in range(new_data.shape[1]):
        buffer.append(new_data[:, i])

    # Solo procesar cuando tenemos ventana completa
    if len(buffer) == WINDOW_SIZE:
        # Convertir buffer a tensor [1,14,T]
        X = np.stack(buffer, axis=1)[None, :, :]  # (1,14,T)
        X = (X - X.mean()) / (X.std() + 1e-8)
        X = X - X.mean(axis=1, keepdims=True)

        X = torch.tensor(X, dtype=torch.float32).to(device)
        with torch.no_grad():
            x45 = projector(X)
            _, out = model(x45)
            pred = out.argmax(1).item()
            label = le.inverse_transform([pred])[0]

        print(f"üîÆ Predicci√≥n: {label}")
        time.sleep(0.25)  # espera simb√≥lica para siguiente lectura